\section{Introduction} 
The main purpose of the present work is to show how to estimate the Hurst exponent for a mono-dimensional time series, using the Detrended Fluctuation Analysis and how to interpret the result in terms of noise. \\
This technique will be developed as a C program and applied to a time series about sun spots.

% A time series is a sequence of data points indexed in time order, mathematically ${ \{ \vec{x}_{i} \in \mathbb{R}^n | i=1, \dots, k \} }$.  


\subsection{Hurst Exponent}
The Hurst exponent is a dimensionless estimator used to evaluate self-similarity and long-range correlation properties of time series. \\
It was introduced by Harold Edwin Hurst to describe the regularities of Nile water level. \\
He defined it as
\begin{equation}
\mathbb{E} \left[\frac{R(N)}{S(N)}\right] \propto N^{H} \quad \text{for } N \to \infty
\end{equation}
where $H \in \left[0, 1 \right] $ is the Hurst exponent, $S (N)$ is the standard deviation and $R(N)$ is the range, the difference between maximum and minimum values of a given time series.

